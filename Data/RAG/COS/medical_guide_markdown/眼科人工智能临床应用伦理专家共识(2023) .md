# 眼科人工智能临床应用伦理专家共识(2023)

《眼科人工智能临床应用伦理专家共识(2023)》专家组 中国医药教育协会数字影像与智能医疗分会，中国医药教育协会智能医学专业委员会

通信作者：邵毅，freebee99@163.com；杨卫华，benben0606@139.com；刘祖国，zuguoliu@xmu.edu.com

【摘要】人工智能(AI)已广泛用于眼部相关疾病的辅助诊断、治疗过程监测和预后判断，随着AI技术在眼科诊疗中应用研究的不断发展，AI的作用日益受到关注。眼睛是由神经组织、肌肉组织、腺体组织和骨组织等组成的复杂感觉器官，其解剖的透明性特点为眼科疾病及部分全身疾病诊断的检查提供了可视化条件，为AI技术的广泛应用奠定了医工交叉研究的基础，使眼科成为AI技术在医学诊疗中应用的主要领域。然而，AI-医疗交叉研究涉及人体大数据和影像结果的使用，其临床应用面临诸多伦理问题，而目前AI与医务人员对AI在医学研究中应用的伦理规范意识尚未建立，各管理层面对相关的伦理规范指导性和监管系统尚未完全形成。中国医药教育协会数字影像与智能医疗分会、中国医药教育协会智能医学专委会组织眼科专家、AI相关专家和科技伦理相关专家组成“眼科人工智能临床应用伦理专家共识(2023)”专家组，针对AI在眼科应用临床实践中存在的法律法规进行复习，对存在的伦理风险进行多维度、多层次梳理、讨论并提出建议或解决方案，目的是在保障患者数据安全和个人权益的同时，提高医务人员工作质量和效率，推动我国眼科AI的临床应用和发展。

【关键词】 人工智能；眼科；伦理；临床应用

基金项目：国家自然科学基金项目（82160195、61906066）；江西省双千计划科技创新高端人才项目（20223BBH80014）；江西省重大（重点）研发专项计划项目（20181BBG70004、20203BBG73059）；江西省杰出青年基金项目（20192BCBL23020）

国际实践指南注册：http://www.guidelines-redistry.cn/,IPGRP-2022CN537

DOI: 10.3760/cma.j.cn115989-20220905-00414

Expert consensus for ethics of clinical application of artificial intelligence in ophthalmology (2023)

Expert Workgroup of Expert consensus for ethics of clinical application of artificial intelligence in ophthalmology (2023); Digital Imaging and Intelligent Medicine Branch of China Medical Education Association, Intelligent Medicine Special Committee of China Medical Education Association
Corresponding authors: Shao Yi, Email: freebee99@163.com; Department of Ophthalmology, the First Affiliated Hospital of Nanchang University, Nanchang 330006, China
Yang Weihua, Email: benben0606 @ 139. com; Institute of Bigdata and Artificial Intelligence in Ophthalmology, Shenzhen Eye Hospital, Jinan University, Shenzhen 518040, China
Liu Zuguo, Email: zuguoliu@xmu.edu.com; Xiamen Eye Center of Xiamen University, The Affiliated Xiang'an Hospital of Xiamen University, Eye Institute of Xiamen University, Fujian Provincial Key Laboratory of Ophthalmology and Visual Science, Xiamen 361102, China

[Abstract] Artificial intelligence (AI) has been widely applied in computer-assisted diagnosis, monitoring of managing procedure and evaluation of prognosis for eye diseases recently. With a rapid development of AI in ophthalmology, the application of AI in clinical practices is receiving increasing attention. Eye is an important and complicated sense organ of human composed of many tissues, such as nerve tissue, muscle tissue, glandular tissue and bone etc. The transparency of eye provides a condition of visualization for imaging examination of ocular and systemic diseases and this is an important basis of AI diagnosis. However, on one hand, AI-assisted diagnosis of eye or systemic diseases based on use of big data and images from human eyes faces some challenges of medical ethics. On the other hand, the norm-based ethics of AI-medical practice has not yet been established so far. Herein, based on the current

situation of AI application in clinical use and research of ophthalmology, an Expert consensus for ethics of clinical application of artificial intelligence in ophthalmology (2023) was drawn up by a consensus expert group comprising senior ophthalmologists, AI developers and medical ethics researchers on the basis of summarization of the existing ethical, legal problems and some documents, extensive investigation and discussion to provide suggestions for the standardized construction of AI clinical application, which expected to safeguard the rights and interests of patients, improve the work quality and efficiency and promote the development of AI application in ophthalmology.

[Key words] Artificial intelligence; Ophthalmology; Ethics; Clinical practice

Fund program: National Natural Science Foundation of China (82160195, 61906066); Jiangxi Double- Thousand Plan High-Level Talent Project of Science and Technology Innovation (20223BBH80014); Key R & D Program of Jiangxi Province (20181BBG70004, 20203BBG73059); Outstanding Youth Fund Project of Jiangxi Province (20192BCBL23020)

International Practice Guidelines register: http://www.guidelines-redistry.cn/, IPGRP-2022CN537

DOI:10.3760/cma.j.cn115989-20220905-00414

1《眼科人工智能临床应用伦理专家共识（2023）》制定背景

随着医工学科交叉研究的不断进步，在人工智能(artificial intelligence, AI)技术的迅速发展和驱动下，AI特别是深度学习(deep learning, DL)在医疗保健和诊疗领域的应用范围得到快速扩展；同时，利用机器学习(machine learning, ML)对临床数据进行自动化分析的研究报告日益增加，AI研究与临床医疗的结合已成为医学研究热点。目前，AI技术在医疗大数据分析领域中发挥着重要作用，已被证明接近甚至优于不同医学专业的临床专家[1]，眼的组织构成包括神经组织和细胞、眼肌组织、血管组织、腺体组织等，是人类解剖和功能最为复杂和最为重要的感觉器官，而眼睛具有透明的解剖结构的特殊性也使得眼睛成为眼科疾病、甚至是部分全身性疾病在眼部的表现得以可视化的唯一器官。因此，眼科疾病的检查和诊断以眼科可视化影像学检查为主，图像精细、信息量大，可以提供多模态、多病程阶段、大量眼部疾病的图像，为AI在眼科疾病的辅助诊疗中发挥作用奠定了重要基础，鉴于眼科影像数据的多样性及获取的便捷性成为AI研究的热点。

AI技术在眼科医疗中的应用十分广泛，包括眼前节相关疾病的诊断与治疗[2]、青光眼疾病特征的呈现及诊断[2]、白内障的诊断和治疗过程监控[3]、视网膜相关病变的筛查及辅助诊断[4]，以及利用眼底照相对心血管疾病危险因素进行预测和评估[5]等。另外，目前眼科一直是AI技术在医学领域中应用的前沿领域，世界上第一个获得美国食品药品监督管理局批准的AI医疗设备IDx-DR即为用于糖尿病视网膜病变(diabeticretinopathy,DR)筛查的AI系统。2020年8月，“糖尿病视网膜病变分析软件”和“糖尿病视网膜

病变眼底图像辅助诊断软件”获得国家药品监督管理局批准[6]。因此，可以预测加强医工交叉研究，加快AI技术在眼科的临床应用以及发展创新仍然是未来的大趋势。

然而，AI的临床应用通常涉及人体研究来源的大数据、大量预测因素、与大量不同来源或类型数据相关的预测问题及其可能的解决方案等，故有研究者提出相关质疑，认为AI在临床医学中的过度使用有可能导致AI-医学诊疗作用被过度放大，若在AI的应用过程中缺乏适当的专业指导或合理知识性引导，可能会带来不良结果，如导致误诊、漏诊或引发医学AI应用过程中的相关伦理问题[7]。另外，目前正处于开发阶段的部分用于医学的AI系统无法保障其在临床诊疗以及患者护理中的安全性、有效性及公平公正性，其性能无法得到有效评估，且相关监管部门也缺乏对医学AI系统进行审查监督的统一标准[8]。

当前，医务人员和患者对眼科AI临床应用的接受程度也存在一定的差异。最新调查结果显示，我国眼科医务人员对AI的理解水平高于其他医学临床专科的技术人员。虽然大多数眼科受访者表示没有任何眼科AI经验，但其对眼科AI的接受程度普遍较高[9]。因此，有必要在其他医学临床专科技术人员和患者中普及眼科AI知识教育，并加强对该领域医学伦理问题的研究，以促进AI技术在眼科临床应用中的广泛推广和健康发展。

在全球新冠肺炎疫情期间及其他重大疫情中，医学AI应用模式在临床应用的必要性及风险性同时并存。新冠肺炎疫情和其他突发事件的发生对全民医疗保健和诊疗模式产生了重大影响，并加速了数字技术的发展和应用。AI技术在医疗保健行业的应用充满了机遇与挑战，机遇主要包括基于眼科影像的AI技术

辅助临床医务人员进行诊疗决策，以改善疾病诊断和治疗的有效性；提高患者在临床诊疗中的参与度，提升医疗服务质量和效率；提高医疗系统运营效率并降低医疗成本；提高医疗保健行业的生产力和创造新的就业机会等，其面临的挑战主要包括系统使用AI所涉及的医学伦理问题和问责制度、数据安全和患者隐私问题、医疗行业的管理监管问题、医务人员培训和继续教育及转型的巨大压力等。

AI技术在眼科医疗中应用的日益广泛引起了行业相关研究者和管理者的广泛关注，提出在眼科AI临床应用的过程中除应遵守现有的法律法规外，还需要主动遵守相关的伦理规范。基于此，制定相关行业的基本共识和规范、提高研究者对AI在临床医学诊疗中的应用伦理意识、对AI在眼科的临床应用（包括临床应用前的AI模型研究）中可能出现的或应遵循的伦理问题提出相关建议及解决方案势在必行，只有规范使用AI-医疗交叉技术，才能帮助眼科专业医务人员和研究人员更好地应对机遇与挑战，保障眼科AI技术在患者中的信任度，最终推动眼科AI的临床应用和发展。

## 2 共识制定方法

基于目前AI技术在眼科临床应用及大数据利用中存在的有关伦理问题，中国医药教育协会数字影像与智能医疗分会、中国医药教育协会智能医学专委会组织眼科临床医学专家、AI研究专家和有关医学或科技伦理学研究专家于2022年5月成立《眼科人工智能临床应用伦理专家共识（2023）》（简称《共识》）撰写组，于2022年6月6日对全国AI在眼科医疗中的应用研究者进行调查，收集并整理相关领域中涉及的医学伦理问题及在相关技术临床应用中面临的困难。由于AI在临床医学应用中尚未形成统一的可遵守的伦理规范，专家组在认真学习国内外AI与医学交叉相关研究文献、基于医学大数据和人工智能AI的相关研究文献和医学伦理法律法规的基础上，召开线下和线上会议，针对收集的AI在眼科临床应用中的伦理问题进行充分讨论和论证，包括眼科AI模型建立的伦理要求和眼科AI临床应用的伦理要求，由执笔小组成员撰写《共识》初稿，初稿形成后通过电子邮件和微信方式由各位专家独立阅读并提出修改意见，分别提交至《共识》撰写组核心成员，修改意见经过整理并通过微信、邮件方式和线上会议进行讨论和归纳，《共识》修改期间得到多位医学伦理专家的建议和指导，最终完成《共识》终稿，旨在改善医务人员对相关领域涉及的伦

理道德规范的认知。本共识制定过程历时半年余。

## 3 眼科AI临床应用的伦理要求

### 3.1 眼科AI模型建立的伦理要求

#### 3.1.1 非AI要素的要求 在眼科AI模型设计和应用研究过程中，非AI相关要素的报告应遵循TRIPOD2015(Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis)指南[10]，该指南旨在确保设计和应用过程中重要信息报告的完整性及透明性。眼科AI模型设计和应用研究过程中，非AI相关要素的报告建议包含以下信息：（1）眼科AI模型参与者（应用对象）相关的信息，如参与者的适应证和禁忌证标准、一般特征等；（2）眼科AI模型中眼病评估结局指标的定义，包括其评估方法及评估时间；（3）眼科AI模型中所用的眼病相关评估因素的定义，包括其评估方法及评估时间；（4）眼科AI模型的开发流程、使用方法以及执行过程。

#### 3.1.2 AI要素的要求 使用DL技术开发的眼科AI模型通常被称为“黑匣子”，与其相关的方法和报告极少。眼科AI模型的设计和应用过程中应遵循以下原则：（1)必须遵守眼科AI模型研究中已存在的方法标准，并对现有的眼科AI模型方法进行客观中立的评价和比较，选择适用于当前情况的最优临床标准；(2)基于AI或ML等技术开发的眼科AI模型在用于常规眼科医疗实践之前，必须针对不同情况进行适当的开发及评估，达不到临床要求的AI模型必须进行新模型的研发；(3)在现有证据的基础上，应当完整、透明地报告眼科AI模型研究的关键环节，以确保眼科AI模型关键环节的公开性和有效性[11]；(4)数据收集应当考虑数据采集、数据预处理、数据标注、数据集构建等活动的质控要求，以保证数据质量和算法设计质量。

### 3.2 眼科AI临床应用的伦理要求

#### 3.2.1 AI研究来源资料的数据管理 眼科领域AI技术的应用过程中须经过大量的数据处理过程，包括数字图像的分类、分析以及评估等[12]，临床诊疗过程结束后也会保存大量数据，可供AI技术分析、学习和训练并进一步优化。在医疗保健领域，数据开放和共享已成为全球的共识和研究发展的趋势。对于大量有价值的数据信息应采取以下措施进行管理：（1）制定有针对性的数据管理和使用协议。首先，应确保患者知晓个人数据的用途及数据处理和分析过程中可能存在的利益风险，并保障患者数据的知情权、个人控制权及使用权。其次，应确认医院对患者医疗数据的使用权，并承担保护患者隐私和保障医疗数据准确性的责

任，且在使用数据进行各种活动的过程中进行监督。最后，应保留政府为公共利益而使用数据的权利。医院应按照相关法律法规向政府报告关键的患者数据，以便政府创建综合数据库，促进公共卫生研究的发展。(2)政府应建立统一信息标准和数据审核机制，在全国范围内建立标准化的共享数据库，并进行医疗编码标准化建设。另外，数据审核、收集、保存和使用过程中应注意数据来源患者隐私的保护，可以对审计过程中所收集的医疗数据质量进行评估和比较，并根据评估结果对医院相应工作进行评价，促进统一标准的达成。(3)扩大数据集成规模，以实现临床研究对数据应用效率的倍增。政府应大力推动共享数据库的建立，实现数据库的多样性和可利用性，并采取措施提高实际实施者的参与热情，加速数据信息的集成化。政府应整合各种社会资源，以减轻政府投资负担并推动相关产业的快速发展，扩大AI临床应用的经济效益与社会效益[13]。

真实数据作为医学AI研究的重要资料来源，针对相关医学数据采集和质量控制、数据安全、数据隐私、数据知情同意及二次使用授权等问题，监管部门应当采取必要措施加以规范化管理。隐私权是人的一项基本权利，这一基本人权受到AI和大数据分析的极大影响，采取有效措施监管AI临床应用中所使用的大量数据是患者隐私权保护的基本保障，具体措施如下：(1)医院与患者双方应签订相关协议，确保患者对含有隐私信息数据的使用知情权，并对医院使用数据的各种用途给予授权；(2)在某些特殊情况下，如患者对与医院所签订的协议提出质疑时，政府相关监管部门需要参与双方协商，以解决实际情况下患者和医疗机构之间可能引起的矛盾纠纷[12]；(3)加强法制建设与法治监管力度，近年来我国相继出台了《中华人民共和国个人信息保护法》《关于促进和规范健康医疗大数据应用发展的指导意见》等，以规范医学AI技术的应用。

#### 3.2.2 AI临床应用的医疗责任为了保障医疗质量和患者自身权益，以获得良好的临床结果，应对眼科AI技术在患者诊疗过程中的自主性进行分析。其中，至少需要考虑以下2个重要因素：（1)眼科AI使用患者数据的目的；（2）眼科AI造成医疗事故的责任承担[14]。部分AI具有弱自主性，不具有法律关系主体资格，但在未来的AI时代，AI可能具有强自主性，故不能排除此阶段AI可能被赋予法律承担资格，具备享有权利和履行义务的功能。无论是设定医疗AI的民事主体身份，还是把医疗AI当作医生的医疗辅助手

段，都必须有相关的法律文件对医疗AI的诊疗行为进行规范。另外，当前阶段，眼科AI的临床应用及数据处理应透明，以便患者享有个人知情权和个人数据使用决定权[15]。眼科AI辅助诊断技术的临床应用涉及侵入性检查和治疗时，或对于临床决策具有重大影响时（如影响患者治疗方案选择、决定是否进一步采取有创性医疗行为、是否明显增加患者医疗费用等），应遵从以下原则：(1)患者应对诊疗过程中眼科AI的使用知情，并拥有选择是否在诊疗过程中使用眼科AI技术的权利；(2)医院与患者应当签订相关协议，以明确相应责任的划分；(3)监管机构应充分保障各方权利，对出现的医疗纠纷进行公平、公正、公开的处理。

#### 3.2.3 AI来源数据的准确有效 为保障眼科AI临床应用中的有效性和准确性，有必要对相关重要信息进行确认，包括眼科AI的使用环境和预期用途的确定，并评估其潜在影响等[14]。具体要求如下：(1)在眼科AI算法进行分析之前，医务人员应明确眼科AI使用计划，并在临床评估报告中详细描述如何在眼科AI算法分析之前获取、选择和预处理眼部图像。同时，所获得的数据需符合相应标准，在提供和传输数据过程中应符合准确性和可靠性要求[16]。（2）确定眼科AI技术在诊疗中的具体用途，以及眼科AI系统在临床应用中的输入和输出需求。实际操作中需要面对的情况相对复杂，这要求医务人员在不同的特定场景下充分考虑各种自然因素和人为因素，依照实际情况做出决策选择并进行必要的调整。（3）医务人员应清楚、全面地报告并记录眼科AI系统从患者处获得的数据，如患者年龄、性别、影像学数据的图像质量等，以保障诊疗报告的真实性和准确性，便于相关人员进行审查和评估。（4）进行良好背景下眼科AI临床有效性的实验评估，依照标准要求，制定相关实验方案，设计相关变量组和控制组，进行重复实验，记录、分析结果，并对相关干预措施及其影响进行因果推断与分析[17]，推进眼科AI产品的迭代升级。

#### 3.2.4 AI临床应用的安全无害性 与其他医疗设备要求相同，眼科AI系统在临床应用过程中首先应保障患者的人身安全，即遵循医学研究的“不伤害”伦理原则。在伦理道德方面，医务人员有义务维护患者的相关权益，不仅需要保护患者的人身安全，还需要保障他们的整体生活质量，即在尊重患者个人意愿和价值观的同时，确保和维护他们的身心健康[18]。

有关安全性的要求对眼科AI系统的应用至关重要，涉及眼科AI的设计、验证和应用的全过程。眼科AI系统的潜在风险受其预期用途、预期效益、实际输

入内容和实际输出内容以及使用环境的影响，因此在设计、验证、应用眼科AI的过程中应遵循以下标准：（1)数据信息透明性。相关信息包括临床医务人员对眼科AI系统输入数据的需求和限制、眼科AI对输入和输出数据的处理方式和过程，以及在AI系统的预期用途之外可能获得的数据。数据信息公开透明是保障眼科AI临床应用安全的充分条件。（2）应用过程公开性。眼科AI的可解释程度虽然从根本上与数据信息透明性有关，但更多的是指与临床实践相关的实际输出内容。例如，输出内容是否具有临床意义、眼科AI所涉及算法及功能透明度以及对眼科AI系统进行评估实验的验证结果。公共开放的应用过程有利于眼科AI安全性的评估。（3)系统评估有效性。有效性是确保眼科AI技术安全性的充分条件，所以，在临床验证研究前应先对AI系统的有效性进行评估，进而保障眼科AI临床应用的安全性。

#### 3.2.5 AI临床应用的公平公正原则 公平公正性的评估主要是从在群体水平上关注眼科AI临床应用对整体患者的影响，而非局限于对个体患者的影响。基于民族、年龄、性别、收入情况、社会地位等可能造成眼科AI算法偏倚，且存在于整个AI的临床应用过程中，对某些特定群体产生不利影响，造成公平公正性的下降[19]。在真实世界中，由于眼科AI诊疗新技术应用的经济成本较高，有可能损害贫困患者生命健康权利的平等性。在分析眼科AI系统的公平维度时，应关注不同的诊疗背景下不同患者参与眼科AI临床应用的成本效益分析，以评估眼科AI实施的公平公正性[20]避免歧视与偏见，避免损害生命个体的尊严。

在当前AI技术迅速发展的背景下选择眼科AI进行研究设计、验证以及参考标准的选择时，应考虑眼科AI实际应用的方案和地点[14]，并遵循以下原则：(1)确定眼科AI预期用途并进行设计、选择和应用时，需保障患者权益；(2)确定眼科AI的使用范围、使用地区和使用场景时，应确保患者参与眼科AI系统应用的公平公正性，并保障患者获益机会等可能性；(3)进行眼科AI应用参照标准选择时应做到公平公正，在特殊情况下可对所选择的标准进行适当且合理的修改或重新制定；(4)进行模型验证时，可通过比较不同因素如民族、年龄和性别等，对眼科AI系统输出灵敏度或输出特异性进行研究，以评估眼科AI系统临床应用的公平公正性[21]。

《共识》的制定旨在对相关技术和从业人员提出工作建议并提高相关医务人员的伦理规范意识，随着我国关于数据安全、AI技术在医学领域应用中相关安

全管理政策的提出，本《共识》将进一步进行讨论和更新。